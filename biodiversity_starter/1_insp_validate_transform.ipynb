{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# filename variable(s)\n",
    "raw_data_observations = 'observations.csv'\n",
    "raw_data_species_info = 'species_info.csv'\n",
    "\n",
    "#-----Loading Data------\n",
    "def sp_load_df(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        print('DataFrame loaded')\n",
    "        return df\n",
    "    except:\n",
    "        print('DataFrame did not load')\n",
    "    \n",
    "#------Inspect------\n",
    "def summarize(df):\n",
    "    df = df.copy()\n",
    "    missing_data = (df.isna().mean() *100).round(2).to_dict()\n",
    "    print(f'\\n----Column Titles: \\n{list(df.columns)}\\n\\n')\n",
    "    print('----Missing Percentages:\\n')\n",
    "    for key, value in missing_data.items():\n",
    "        print(f'{key}, {value}% missing')\n",
    "    print('\\n----Data Types:\\n\\n', df.dtypes, '\\n\\n')\n",
    "    print(df.describe(include='all'), '\\n\\n')\n",
    "    print(df.info())\n",
    "\n",
    "def col_duplicates(df, col):\n",
    "    df.copy()\n",
    "    count = df[col].value_counts()\n",
    "    count_df = count.reset_index()\n",
    "    duplicates_df = count_df[count_df['count'] > 1]\n",
    "    print(f'Duplicates Dataframe: length = {len(duplicates_df)}')\n",
    "    return duplicates_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Load, Inspect, Clean, Organize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. `observations.csv`\n",
    "\n",
    "`df = sp_load_df(raw_data_observations)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sp_load_df(raw_data_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# count duplicates in scientific_name\n",
    "sci_name_dupl = col_duplicates(df, 'scientific_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_name_dupl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "summarize(sci_name_dupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby approach to sci_names for duplicates\n",
    "df_sci_grouped = df.groupby(['scientific_name','park_name'], as_index=False).observations.sum().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sci_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure observations count didn't change\n",
    "np.sum(df_sci_grouped.observations) == np.sum(df.observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 2. `species_info.csv`\n",
    "\n",
    "`df1 = sp_load_df(raw_data_species_info)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = sp_load_df(raw_data_species_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "summarize(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sort_values(by=['conservation_status', 'scientific_name'], ascending=[True, True]).to_csv('species_info_sort.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_sci_name_dup = col_duplicates(df1, 'scientific_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_sci_name_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare species for merge into observations df\n",
    "\n",
    "# Canis lupus - grey wolf is listed as 'in recovery' and 'endangered' on duplicates\n",
    "# Below status and pick_status is designed to handle instances by selecting the more severe of the two\n",
    "\n",
    "status_priority = {\n",
    "    \"Endangered\": 4,\n",
    "    \"Threatened\": 3,\n",
    "    \"Species of Concern\": 2,\n",
    "    \"In Recovery\": 1,\n",
    "    \"No Concern\": 0,\n",
    "}\n",
    "\n",
    "def pick_status(col: pd.Series) -> str:\n",
    "    # choose the single highest-priority label present for this species\n",
    "    # unknown labels fall back to lowest priority (-1)\n",
    "    return max(col, key=lambda x: status_priority.get(x, -1))\n",
    "\n",
    "spc_agg = (df1\n",
    "    .groupby('scientific_name', as_index=False)\n",
    "    .agg({\n",
    "        'common_names': lambda x: ', '.join(sorted(set(x))),\n",
    "        'category': lambda x: ', '.join(sorted(set(x))),\n",
    "        'conservation_status': pick_status\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_agg.conservation_status = spc_agg.conservation_status.fillna('No Concern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for sci name dups to ensure 1:1 for merge\n",
    "dup_spc_agg = col_duplicates(spc_agg, 'scientific_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Merge DF's on `scientific_name`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df1_merged = df_sci_grouped.merge(\n",
    "    spc_agg,\n",
    "    on='scientific_name',\n",
    "    how='left',\n",
    "    copy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df1_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm no change to obs count for original df)\n",
    "np.sum(df.observations) == np.sum(df_df1_merged.observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Column Variable Modifications \n",
    "\n",
    "Cleaned and Merged DF = `df_df1_merged` Â» `df2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_df1_merged\n",
    "unord_cat_cols = ['scientific_name', 'park_name', 'category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_conv(df, cols):\n",
    "    for col in df[cols]:\n",
    "        df[col] = pd.Categorical(df[col], ordered=False) # seem to need to use the [] for col notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_conv(df2, unord_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered categorical approach for conservation_status\n",
    "\n",
    "df2.conservation_status = pd.Categorical(df2.conservation_status, ((list(status_priority.keys()))[::-1]), ordered=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "summarize(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.conservation_status.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# Final DF for write to feather = `df2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_feather('df_merged.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds311)",
   "language": "python",
   "name": "ds311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
